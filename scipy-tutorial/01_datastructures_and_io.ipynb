{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Multi-dimensional (a.k.a. N-dimensional, ND) arrays (sometimes called “tensors”) are an essential part of computational science. They are encountered in a wide range of fields, including physics, astronomy, geoscience, bioinformatics, engineering, finance, and deep learning. In Python, NumPy provides the fundamental data structure and API for working with raw ND arrays. However, real-world datasets are usually more than just raw numbers; they have labels which encode information about how the array values map to locations in space, time, etc.\n",
    "\n",
    "Xarray doesn’t just keep track of labels on arrays – it uses them to provide a powerful and concise interface. For example:\n",
    "\n",
    "- Apply operations over dimensions by name: `x.sum('time')`.\n",
    "\n",
    "- Select values by label (or logical location) instead of integer location: `x.loc['2014-01-01']` or `x.sel(time='2014-01-01')`.\n",
    "\n",
    "- Mathematical operations (e.g., `x - y`) vectorize across multiple dimensions (array broadcasting) based on dimension names, not shape.\n",
    "\n",
    "- Easily use the split-apply-combine paradigm with groupby: `x.groupby('time.dayofyear').mean()`.\n",
    "\n",
    "- Database-like alignment based on coordinate labels that smoothly handles missing values: `x, y = xr.align(x, y, join='outer')`.\n",
    "\n",
    "- Keep track of arbitrary metadata in the form of a Python dictionary: `x.attrs`.\n",
    "\n",
    "The N-dimensional nature of xarray’s data structures makes it suitable for dealing with multi-dimensional scientific data, and its use of dimension names instead of axis labels (`dim='time'` instead of `axis=0`) makes such arrays much more manageable than the raw numpy ndarray: with xarray, you don’t need to keep track of the order of an array’s dimensions or insert dummy dimensions of size 1 to align arrays (e.g., using np.newaxis).\n",
    "\n",
    "The immediate payoff of using xarray is that you’ll write less code. The long-term payoff is that you’ll understand what you were thinking when you come back to look at it weeks or months later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data structures\n",
    "\n",
    "xarray mainly provides two types: `DataArray` and `Dataset`. The `DataArray` class attaches dimension names, coordinates and attributes to multi-dimensional arrays while `Dataset` combines multiple arrays.\n",
    "\n",
    "Both classes are normally created by reading data, but to understand them let's first look at creating them programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataArray\n",
    "\n",
    "The `DataArray` class is used to attach a name, dimension names, labels, and attributes to an array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's create a `DataArray` named `a` with two dimensions (named `x` and `y`) from a `numpy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.DataArray(\n",
    "    np.ones((3, 4, 2)),\n",
    "    dims=(\"x\", \"y\", \"z\"),\n",
    "    name=\"a\",\n",
    "    coords={\"z\": [-1, 1], \"u\": (\"x\", [0.1, 1.2, 2.3])},\n",
    "    attrs={\"attr\": \"value\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we used a 3x4 `numpy` array with all values being equal to `1`, but it can be anything that either behaves like a `numpy` array or can be coerced to a `numpy` array using `numpy.array`.\n",
    "\n",
    "We also passed a sequence (a tuple here, but could also be a list) containing the dimension names `x` and `y` to `dims`. In case we have only a single dimension we can also pass just the dimension name:\n",
    "```python\n",
    "xr.DataArray([1, 1], dims=\"x\")\n",
    "```\n",
    "\n",
    "The dimension names (and the array's `name`) can be anything that fits into a python `set` (i.e. calling `hash()` on it doesn't raise an error), but to be useful they should be strings.\n",
    "\n",
    "`coords` is a [dict-like](https://docs.python.org/3/glossary.html#term-mapping) container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings). We will look at its format later.\n",
    "\n",
    "We can also attach arbitrary metadata (attributes) to the `DataArray` by passing a dict-like to the `attrs` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### string representations\n",
    "\n",
    "Now that we have the `DataArray` we can look at its string representation.\n",
    "\n",
    "xarray has two representation types: `\"html\"` (which is only available in notebooks) and `\"text\"`. To choose between them, use the `display_style` option.\n",
    "\n",
    "Let's first look at the text representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.set_options(display_style=\"text\")\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It consists of:\n",
    "- the name of the `DataArray` (`'a'`). If we didn't provide a name, this will be omitted.\n",
    "- the dimensions of the array `(x: 3, y: 4)`: this tells us that the first dimension is named `x` and has a size of `3` while the second dimension is named `y` and has a size of `4`\n",
    "- a preview of the data\n",
    "- a (unordered) list of coordinates or dimensions with coordinates with one item per line. Each item has a name, one or more dimensions in parentheses, a dtype and a preview of the values. Also, if it is a dimension coordinate, it will be marked with a `*`.\n",
    "- a alphabetically sorted list of dimensions without coordinates\n",
    "- a (unordered) list of attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `\"html\"` representation looks similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.set_options(display_style=\"html\")\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "except the data preview was collapsed to a single line (we can expand it by clicking on the symbol on the left) and the dimensions are marked by a bold font instead of a `*` prefix.\n",
    "\n",
    "Except when explaining the text representation we will use the HTML representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created the `DataArray`, we can look at its data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coordinates\n",
    "\n",
    "As mentioned above, `coords` is a dict-like mapping names to values. These values can be either\n",
    "\n",
    "- another `DataArray` object\n",
    "- a tuple of the form `(dims, data, attrs)` where `attrs` is optional. This is roughly equivalent to creating a new `DataArray` object with `DataArray(dims=dims, data=data, attrs=attrs)`\n",
    "- a `numpy` array (or anything that can be coerced to one using `numpy.array`).\n",
    "\n",
    "Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.DataArray(\n",
    "    np.ones((3, 4)),\n",
    "    dims=(\"x\", \"y\"),\n",
    "    coords={\n",
    "        \"x\": [\"a\", \"b\", \"c\"],\n",
    "        \"y\": np.arange(4),\n",
    "        \"u\": (\"x\", np.arange(3), {\"attr1\": 0}),\n",
    "    },\n",
    ")\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we assigned labels to the `x` and `y` dimensions and also created a coordinate named `u` along `x` with its own metadata (click on the sheet icon to look at them).\n",
    "\n",
    "The difference between the dimension labels (dimension coordinates) and normal coordinates is that for now it only is possible to use indexing operations (`sel`, `reindex`, etc) with dimension coordinates. Also, while coordinates can have arbitrary dimensions, dimension coordinates have to be one-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "`Dataset` objects collect multiple data variables, each with possibly different dimensions.\n",
    "\n",
    "The constructor of `Dataset` takes three parameters:\n",
    "- `data_vars`: dict-like mapping names to values. It has the format described in [coordinates](#coordinates) except we need to use either `DataArray` objects or the tuple syntax since we have to provide dimensions\n",
    "- `coords`: same as for `DataArray`\n",
    "- `attrs`: same as for `Dataset`\n",
    "\n",
    "For example, let's create a `Dataset` with two variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset(\n",
    "    data_vars={\n",
    "        \"a\": ((\"x\", \"y\"), np.ones((3, 4))),\n",
    "        \"b\": (\"t\", np.full((8,), 3), {\"attr\": \"value\"}),\n",
    "    },\n",
    "    coords={\n",
    "        \"x\": [-1, 0, 1],\n",
    "    },\n",
    "    attrs={\"attr\": \"value\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### string representations\n",
    "\n",
    "Let's again first look at the text representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.set_options(display_style=\"text\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It consists of\n",
    "- a summary of all dimensions in the dataset and their lengths\n",
    "- a unordered list of coordinates (same format as the `DataArray`)\n",
    "- a unordered list of dimensions without coordinates\n",
    "- a unordered list of data variables: each item has the same format as the coordinates with the exception of the dimension mark (`*`)\n",
    "\n",
    "Again, the HTML representation is similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.set_options(display_style=\"html\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with `DataArray`, a `Dataset` really becomes useful once we assign coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.Dataset(\n",
    "    data_vars={\n",
    "        \"a\": ((\"x\", \"y\"), np.ones((3, 4))),\n",
    "        \"b\": ((\"t\", \"x\"), np.full((8, 3), 3)),\n",
    "    },\n",
    "    coords={\n",
    "        \"x\": [\"a\", \"b\", \"c\"],\n",
    "        \"y\": np.arange(4),\n",
    "        \"t\": pd.date_range(\"2020-07-05\", periods=8, freq=\"D\"),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have variables with different values along the same dimension, we can't use the shortcut syntax anymore. Instead, we need to use `DataArray` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a = np.arange(1, 4)\n",
    "x_b = np.arange(-1, 3)\n",
    "\n",
    "a = xr.DataArray(np.linspace(0, 1, 3), dims=\"x\", coords={\"x\": x_a})\n",
    "b = xr.DataArray(np.zeros(4), dims=\"x\", coords={\"x\": x_b})\n",
    "\n",
    "xr.Dataset(data_vars={\"a\": a, \"b\": b})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which combines the coordinates and fills in floating-point `nan` values for missing data (converting the data type to `float` in the process). For example, `b` doesn't have a value for `x == 3` so `nan` was used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roundtripping and I/O\n",
    "\n",
    "Typically, `DataArray` and `Dataset` objects are not created programmatically but instead by converting from / to other libraries such as `pandas` or by reading from data storage formats such as `netcdf` or `zarr`.\n",
    "\n",
    "To convert from / to `pandas`, we can use the `to_xarray` methods on `pandas` objects or the `to_pandas` methods on `xarray` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(np.ones((10,)), index=list(\"abcdefghij\"))\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = series.to_xarray()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also control what `pandas` object is used by calling `to_series` / `to_dataframe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset(data_vars={\"a\": (\"x\", np.arange(5)), \"b\": ((\"x\", \"y\"), np.ones((5, 4)))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`to_series`**:\n",
    "This will always convert `DataArray` objects to `pandas.Series`, using a `MultiIndex` for higher dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.a.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.b.to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`to_dataframe`**:\n",
    "This will always convert `DataArray` or `Dataset` objects to a `pandas.DataFrame`. Note that `DataArray` objects have to be named for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.a.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since columns in a `DataFrame` need to have the same index, they are broadcasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O\n",
    "\n",
    "- netcdf / pseudonetcdf (open_dataset / open_mfdataset, to_netcdf / save_mfdataset)\n",
    "- zarr (open_zarr, to_zarr)\n",
    "- rasterio (open_rasterio)\n",
    "\n",
    "Scientific data usually is \n",
    "\n",
    "### netcdf\n",
    "\n",
    "To read / write to `netcdf` files, use the `open_dataset` / `open_dataarray` functions and the `to_netcdf` method.\n",
    "\n",
    "Let's first create some datasets and write them to disk using `to_netcdf`, which takes the path we want to write to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = xr.Dataset(\n",
    "    data_vars={\n",
    "        \"a\": ((\"x\", \"y\"), np.random.randn(4, 2)),\n",
    "        \"b\": ((\"z\", \"x\"), np.random.randn(6, 4)),\n",
    "    },\n",
    "    coords={\n",
    "        \"x\": np.arange(4),\n",
    "        \"y\": np.arange(-2, 0),\n",
    "        \"z\": np.arange(-3, 3),\n",
    "    },\n",
    ")\n",
    "ds2 = xr.Dataset(\n",
    "    data_vars={\n",
    "        \"a\": ((\"x\", \"y\"), np.random.randn(7, 3)),\n",
    "        \"b\": ((\"z\", \"x\"), np.random.randn(2, 7)),\n",
    "    },\n",
    "    coords={\n",
    "        \"x\": np.arange(6, 13),\n",
    "        \"y\": np.arange(3),\n",
    "        \"z\": np.arange(3, 5),\n",
    "    },\n",
    ")\n",
    "\n",
    "ds1.to_netcdf(\"ds1.nc\")\n",
    "ds2.to_netcdf(\"ds2.nc\")\n",
    "\n",
    "ds1.a.to_netcdf(\"da1.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading those files is just as simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataset(\"ds1.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataarray(\"da1.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zarr\n",
    "\n",
    "`zarr` files can be written with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.to_zarr(\"ds1.zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then read the created file with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_zarr(\"ds1.zarr\", chunks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting the `chunks` parameter to `None` avoids `dask` (more on that in a later session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
