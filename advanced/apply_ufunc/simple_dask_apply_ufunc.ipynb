{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a8ff28a-4be3-469f-8cf4-9297e71cc4ca",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Handling dask arrays\n",
    "\n",
    "We have previously worked over applying functions to NumPy arrays contained in Xarray objects.\n",
    "`apply_ufunc` also lets you easily perform many of the steps involving in applying \n",
    "functions that expect and return Dask arrays.\n",
    "\n",
    "Learning goals:\n",
    "- Learn that `apply_ufunc` can automate aspects of applying computation functions on dask arrays\n",
    "\n",
    "```{tip}\n",
    "We'll reduce the length of error messages using `%xmode minimal` See the [ipython documentation](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-xmode) for details.\n",
    "```\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32335e2d-9f8c-490d-a991-2bcabbdf3d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%xmode minimal\n",
    "\n",
    "import dask\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "xr.set_options(display_expand_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e511efdf-1f39-4dcf-a111-660eeca2eb8c",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "First lets set up a `LocalCluster` using [dask.distributed](https://distributed.dask.org/).\n",
    "\n",
    "You can use any kind of dask cluster. This step is completely independent of\n",
    "xarray. While not strictly necessary, the dashboard provides a nice learning\n",
    "tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5df0bd-4fa2-43b2-942c-fb6ce2a55d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa9663b-028a-4639-be90-5576f88d1bfa",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "<p>&#128070</p> Click the Dashboard link above. Or click the \"Search\" button in the dashboard.\n",
    "\n",
    "Let's test that the dashboard is working..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419e2a6-9ff7-4d33-b6da-243210c34a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array\n",
    "\n",
    "dask.array.ones((1000, 4), chunks=(2, 1)).compute()  # should see activity in dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6abae80-004a-481f-9b1a-c476de951ef0",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Let's open a dataset. We specify `chunks` so that we create a dask arrays for the DataArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74da273-e603-442f-9970-ef3eb17a3ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.tutorial.open_dataset(\"air_temperature\", chunks={\"time\": 100})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b21b09-3ebb-4efb-9c57-44bf587ba92d",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## A simple example\n",
    "\n",
    "All the concepts from applying numpy functions carry over.\n",
    "\n",
    "However the handling of dask arrays needs to be explicitly activated.\n",
    "\n",
    "There are three options for the `dask` kwarg.\n",
    "\n",
    "```\n",
    "    dask : {\"forbidden\", \"allowed\", \"parallelized\"}, default: \"forbidden\"\n",
    "        How to handle applying to objects containing lazy data in the form of\n",
    "        dask arrays:\n",
    "\n",
    "        - 'forbidden' (default): raise an error if a dask array is encountered.\n",
    "        - 'allowed': pass dask arrays directly on to ``func``. Prefer this option if\n",
    "          ``func`` natively supports dask arrays.\n",
    "        - 'parallelized': automatically parallelize ``func`` if any of the\n",
    "          inputs are a dask array by using :py:func:`dask.array.apply_gufunc`. Multiple output\n",
    "          arguments are supported. Only use this option if ``func`` does not natively\n",
    "          support dask arrays (e.g. converts them to numpy arrays).\n",
    "```\n",
    "\n",
    "We will work through the following two:\n",
    "\n",
    "1. `dask=\"allowed\"` Dask arrays are passed to the user function. This is a good\n",
    "   choice if your function can handle dask arrays and won't compute the result unless \n",
    "   explicitly requested.\n",
    "2. `dask=\"parallelized\"`. This applies the user function over blocks of the dask\n",
    "   array using `dask.array.blockwise`. This is useful when your function cannot\n",
    "   handle dask arrays natively (e.g. scipy API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26800228-97cc-4f35-baf8-a5face577543",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Expect an error here\n",
    "def squared_error(x, y):\n",
    "    return (x - y) ** 2\n",
    "\n",
    "\n",
    "xr.apply_ufunc(squared_error, ds.air, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c1b9f-f436-414c-944b-fa134837ee32",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "  \n",
    "A good thing to check is whether the applied function (here `squared_error`) can handle pure dask arrays. \n",
    "To do this call  `squared_error(ds.air.data, 1)` and make sure of the following:\n",
    "1. That you don't see any activity on the dask dashboard\n",
    "2. That the returned result is a dask array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6ffab-5b27-4169-b4c3-ce605707ba9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "squared_error(ds.air.data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c17b34-7fd9-45ef-9f71-041fc8b16fdf",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "Since `squared_error` can handle dask arrays without computing them, we specify\n",
    "`dask=\"allowed\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0806da-b6ea-4618-8394-b2e888f4c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqer = xr.apply_ufunc(\n",
    "    squared_error,\n",
    "    ds.air,\n",
    "    1,\n",
    "    dask=\"allowed\",\n",
    ")\n",
    "sqer  # dask-backed DataArray! with nice metadata!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1418c06-e1f8-4db8-bdf5-a4e23f6524e1",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Understanding what's happening\n",
    "\n",
    "Let's again use the wrapper trick to understand what `squared_error` receives.\n",
    "\n",
    "We see that it receives a dask array (analogous to the numpy array in the previous example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a5eb4-c6e9-445f-87bb-5bcaa653439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(x, y):\n",
    "    print(f\"received x of type {type(x)}, shape {x.shape}\")\n",
    "    print(f\"received y of type {type(y)}\")\n",
    "    return squared_error(x, y)\n",
    "\n",
    "\n",
    "xr.apply_ufunc(wrapper, ds.air, 1, dask=\"allowed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b0d1c-8bf3-4ddb-aa5f-e2ca70415ad6",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Reductions and core dimensions\n",
    "\n",
    "`squared_error` operated on a per-element basis. How about a reduction like `np.mean`?\n",
    "\n",
    "Such functions involve the concept of \"core dimensions\". One way to think about core dimensions is to consider the smallest dimensionality of data necessary to apply the function.\n",
    "\n",
    "For using more complex operations that consider some array values collectively,\n",
    "itâ€™s important to understand the idea of **core dimensions**. \n",
    "Usually, they correspond to the fundamental dimensions over\n",
    "which an operation is defined, e.g., the summed axis in `np.sum`. A good clue\n",
    "that core dimensions are needed is the presence of an `axis` argument on the\n",
    "corresponding NumPy function.\n",
    "\n",
    "With `apply_ufunc`, core dimensions are recognized by name, and then moved to\n",
    "the last dimension of any input arguments before applying the given function.\n",
    "This means that for functions that accept an `axis` argument, you usually need\n",
    "to set `axis=-1`\n",
    "\n",
    "```{tip} Exercise\n",
    "\n",
    "Use `dask.array.mean` as an example of a function that can handle dask\n",
    "arrays and uses an `axis` kwarg. \n",
    "```\n",
    "\n",
    "```{tip} Solution\n",
    ":class: dropdown\n",
    "```python\n",
    "def time_mean(da):\n",
    "    return xr.apply_ufunc(\n",
    "        dask.array.mean,\n",
    "        da,\n",
    "        input_core_dims=[[\"time\"]],\n",
    "        dask=\"allowed\",\n",
    "        kwargs={\"axis\": -1},  # core dimensions are moved to the end\n",
    "    )\n",
    "\n",
    "\n",
    "time_mean(ds.air)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7952ceb1-8402-41d1-8813-31228c3e9ae6",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "Again, this is identical to the built-in `mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c343d01-cdf6-4e48-a349-606f06c4c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_mean(da):\n",
    "    return xr.apply_ufunc(\n",
    "        dask.array.mean,\n",
    "        da,\n",
    "        input_core_dims=[[\"time\"]],\n",
    "        dask=\"allowed\",\n",
    "        kwargs={\"axis\": -1},  # core dimensions are moved to the end\n",
    "    )\n",
    "\n",
    "\n",
    "ds.air.mean(\"time\").identical(time_mean(ds.air))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abf7aa7-e1e6-4935-9d59-58d4f587135c",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Automatically parallelizing dask-unaware functions\n",
    "\n",
    "A very useful `apply_ufunc` feature is the ability to apply arbitrary functions\n",
    "in parallel to each block. This ability can be activated using\n",
    "`dask=\"parallelized\"`. \n",
    "\n",
    "Again xarray needs a lot of extra metadata, so depending\n",
    "on the function, extra arguments such as `output_dtypes` and `output_sizes` may\n",
    "be necessary.\n",
    "\n",
    "We will use `scipy.integrate.trapz` as an example of a function that cannot\n",
    "handle dask arrays and requires a core dimension. If we call `trapz` with a dask\n",
    "array, we get a numpy array back that is, the values have been eagerly computed.\n",
    "This is undesirable behaviour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a04e83-c061-4e14-80d9-b73d6c36981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.integrate\n",
    "\n",
    "sp.integrate.trapz(\n",
    "    ds.air.data, axis=ds.air.get_axis_num(\"lon\")\n",
    ")  # does NOT return a dask array, you should see activity on the dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f518099f-7778-4f0a-9d40-950968c651d5",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "Let's activate automatic parallelization with `dask=\"parallelized\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faef8dd-13b0-46c6-a19a-08e5e095fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated = xr.apply_ufunc(\n",
    "    sp.integrate.trapz,\n",
    "    ds,\n",
    "    input_core_dims=[[\"lon\"]],\n",
    "    kwargs={\"axis\": -1},\n",
    "    dask=\"parallelized\",\n",
    ")\n",
    "integrated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec8e13e-77e0-4e46-a32d-dafa5da6fa6a",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "And make sure the returned data is a dask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9e6e4-5011-4968-84f7-befe25c049bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "integrated.air.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e87266-2ff7-452d-b96d-d551d55c5e4e",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "We'll define a function `integrate_lon` for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689909bf-884e-4dbd-9e28-ed2cb68f80b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def integrate_lon(ds):\n",
    "    return xr.apply_ufunc(\n",
    "        sp.integrate.trapz,\n",
    "        ds,\n",
    "        input_core_dims=[[\"lon\"]],\n",
    "        kwargs={\"axis\": -1},\n",
    "        dask=\"parallelized\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348a4c4-b36f-4ad8-8549-fce35ef429dd",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Understanding what is happening\n",
    "\n",
    "\n",
    "It is very important to understand what `dask=\"parallelized\"` does. It is quite convenient and works well for \"blockwise\" or \"embarrassingly parallel\" operations.\n",
    "\n",
    "These are operations where one block or chunk of the output array corresponds to one block or chunk of the input array. Specifically, the blocks or chunks of the _core dimension_ is what matters.\n",
    "\n",
    "Let's look at the dask repr for `ds` and note chunksizes are (100,25,53) for a array with shape (2920, 25, 53). This means that each block or chunk of the array contains all `lat`, `lon` points and a subset of `time` points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d737df-8a6b-4244-bef7-c3464a1b65da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.air.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b66790-4c7c-4902-aa3b-89f92c5641b5",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "The core dimension for `trapz` is `lon`, and there is only one chunk along `lon`. This means that integrating along `lon` is a \"blockwise\" or \"embarrassingly parallel\" operation and `dask=\"parallelized\"` works quite well. \n",
    "\n",
    "```{tip} Question\n",
    "Do you understand why `integrate(ds)` when `ds` has a single chunk along `lon` is a \"embarassingly parallel\" operation?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4707d4-f596-47a8-8a3b-6a4a157f0759",
   "metadata": {
    "tags": []
   },
   "source": [
    "```{tip} Exercise\n",
    "Apply the integrate function to `ds` after rechunking to have a different chunksize along `lon` using `ds.chunk(lon=4)` (for example). What happens?\n",
    "```\n",
    "```{tip} Solution\n",
    ":class: dropdown\n",
    "\n",
    "`apply_ufunc` complains that it cannot automatically parallelize because the dataset `ds` is now chunked along the core dimension `lon`. You should see the following error:\n",
    "\n",
    "    ValueError: dimension lon on 0th function argument to apply_ufunc with dask='parallelized' \n",
    "    consists of multiple chunks, but is also a core dimension. To fix, either rechunk \n",
    "    into a single array chunk along this dimension, i.e., \n",
    "    ``.chunk(dict(lon=-1))``, or pass ``allow_rechunk=True`` in ``dask_gufunc_kwargs`` \n",
    "    but beware that this may significantly increase memory usage.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3618181-7432-409e-95e7-d7bc4cc567ce",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Clean up the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b375c8a-b7ef-47a6-b007-1fc2f34a2cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71492531-4eda-4c47-86e5-dad033c22751",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## More\n",
    "\n",
    "1. https://docs.xarray.dev/en/stable/examples/apply_ufunc_vectorize_1d.html\n",
    "2. https://docs.dask.org/en/latest/array-best-practices.html\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
